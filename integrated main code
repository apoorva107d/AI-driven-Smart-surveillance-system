import cv2
import numpy as np
import joblib
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import pygame
import warnings
from tensorflow.keras.models import load_model  # type: ignore
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input  # type: ignore

warnings.filterwarnings("ignore")

# defining Constants
IMG_SIZE = 128
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

pygame.mixer.init()
alert_sound = pygame.mixer.Sound("alert.wav")  # Load the alert sound

# ======================== Mask Detection ========================
def detect_mask(frame, model):
   
    # Preprocess the entire frame
    processed_frame = preprocess_image(frame)

    # Predict using the mask detection model
    prediction = model.predict(processed_frame, verbose=0)  # Disable prediction logs
    mask_probability = prediction[0][0]  # Probability of "with_mask"
    no_mask_probability = prediction[0][1]  # Probability of "without_mask"

    # Determine the label
    label = "With Mask" if mask_probability > no_mask_probability else "Without Mask"
    color = (0, 255, 0) if label == "With Mask" else (0, 0, 255)

    # Display the label on the frame
    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

    # Play alert sound if no mask is detected
    if label == "With Mask":
        alert_sound.play()

    return frame

def preprocess_image(img):
    img_resized = cv2.resize(img, (128, 128))  # Resizing image to 128x128
    img_preprocessed = preprocess_input(img_resized)  # Preprocessing the image
    return np.expand_dims(img_preprocessed, axis=0)  # Adding batch dimension

# ======================== Violence Detection ========================
def detect_violence(frame, model):
    resized_frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE)) / 255.0
    flattened_frame = resized_frame.flatten().reshape(1, -1)
    prediction = model.predict(flattened_frame)
    label = ["aggressive", "non_aggressive"][prediction[0]]

    cv2.putText(frame, label, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    if label == "aggressive":
        alert_sound.play()

    return frame

# ======================== Weapon Detection ========================
def detect_weapon(frame, model):
    results = model(frame)
    detections = results.xyxy[0].cpu().numpy()  # Moving tensor to CPU first, then converting to NumPy

    weapon_detected = False  # Flag to check if a weapon is detected

    for detection in detections:
        x1, y1, x2, y2, conf, cls = detection
        if conf > 0.7:  #threshold
            weapon_detected = True  # Set flag 
            class_name = ["Automatic Rifle", "Bazooka", "Handgun", "Shotgun", "SMG", "Sniper", "Sword"][int(cls)]
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
            cv2.putText(frame, f"{class_name} {conf:.2f}", (int(x1), int(y1) - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
            
            alert_sound.play()

    if not weapon_detected:
        cv2.putText(frame, "No Weapon Detected", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    return frame


# ======================== Fall Detection ========================
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.pool = nn.MaxPool2d(kernel_size=2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.dropout = nn.Dropout(0.5)
        self.fc1 = nn.Linear(128 * 16 * 16, 256)  # Adjusted for IMG_SIZE=128
        self.fc2 = nn.Linear(256, 2)

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.pool(F.relu(self.bn3(self.conv3(x))))
        x = x.view(x.size(0), -1)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

def preprocess_frame(frame):
    frame_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))  # Resize to 128x128
    frame_normalized = frame_resized / 255.0  # Normalize pixel values to [0, 1]
    frame_tensor = transforms.ToTensor()(frame_normalized).unsqueeze(0).to(DEVICE)  # Convert to tensor
    frame_tensor = frame_tensor.float()  # Ensure the tensor is of type float32
    return frame_tensor

def detect_fall(frame, model):
    input_tensor = preprocess_frame(frame)
    with torch.no_grad():
        output = model(input_tensor)
        _, predicted = torch.max(output, 1)
        label = "Fallen" if predicted.item() == 2 else "Not Fallen"
    cv2.putText(frame, f"Fall: {label}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    # Play alert sound if a fall is detected
    if label == "Fallen":
        alert_sound.play()

    return frame

# ======================== Load Models ========================
def load_models():
    # Loading mask detection model 
    mask_model = load_model("maskkk_detector_cnn.h5")  

    # Loading weapon detection model
    weapon_model = torch.hub.load('ultralytics/yolov5', 'custom', path=r"C:\Users\APOORVA DHIMAN\yolov5\runs\train\exp\weights\best.pt")

    # Loading violence detection model
    violence_model = joblib.load("violence_detector_model.pkl")

    # Loading fall detection model
    fall_model = CNN().to(DEVICE)
    fall_model.load_state_dict(torch.load("fall_detection_model.pth", map_location=torch.device(DEVICE)))
    fall_model.eval()

    return mask_model, weapon_model, violence_model, fall_model

# ======================== Main Function ========================
def main():
    # Load models
    mask_model, weapon_model, violence_model, fall_model = load_models()

    # Initialize video capture
    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Applying all detections by processing the entire frames
        frame = detect_mask(frame, mask_model) 
        frame = detect_violence(frame, violence_model)
        frame = detect_weapon(frame, weapon_model)
        frame = detect_fall(frame, fall_model)

        cv2.imshow("Integrated Detections", frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
